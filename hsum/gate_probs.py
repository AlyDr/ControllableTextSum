# -*- coding: utf-8 -*-
"""gate_probs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K00k79SmvqG4bR8YcgxDc29T0wqARlDP
"""

import torch

# If there's a GPU available...
if torch.cuda.is_available():

    # Tell PyTorch to use the GPU.
    device = torch.device("cuda")

    print('There are %d GPU(s) available.' % torch.cuda.device_count())

    print('We will use the GPU:', torch.cuda.get_device_name(0))

# If not...
else:
    print('No GPU available, using the CPU instead.')
    device = torch.device("cpu")

import csv
import os
import string
import nltk
nltk.download('punkt')
import pandas as pd
from nltk import word_tokenize, ngrams
import numpy as np

!pip install datasets

from datasets import load_dataset

dataset = load_dataset("IlyaGusev/gazeta", split ='test')

punctuations = string.punctuation


# if token is seen, head1, if token is unseen head0
def get_gate_type0(article, summary):
    gate = []
    article_tokens = set(article.lower().split(' '))
    summary_tokens = summary.lower().split(' ')
    for token in summary_tokens:
        if token in punctuations:
            gate.append('-1')
        elif token in article_tokens:
            gate.append('1')
        else:
            gate.append('0')

    assert len(gate) == len(summary_tokens), 'gate length does not match summary length'
    return gate


# if token is unseen and context is unseen, head1, if token is seen and context is seen head0
def get_gate_type2(article, summary):
    gate = []
    article_tokens = set(article.split(' '))
    summary_tokens = summary.split(' ')
    for idx, token in enumerate(summary_tokens):
        if idx < 3:
            gate.append('-1')
        elif token in punctuations:
            gate.append('-1')
        else:
            prefix_wtoken = ' '.join(summary_tokens[idx-2: idx + 1])
            prefix = ' '.join(summary_tokens[idx-2: idx])
            if prefix_wtoken in article:
                gate.append('1')
            elif prefix not in article and token not in article:
                gate.append('0')
            else:
                gate.append('-1')

    assert len(gate) == len(summary_tokens), 'gate length does not match summary length'
    return gate


def get_overlap(inp, out, ngram=2):
    grams_inp = set(ngrams(word_tokenize(inp.lower()), ngram))
    grams_out = set(ngrams(word_tokenize(out.lower()), ngram))

    total = len(grams_out)
    common = len(grams_inp.intersection(grams_out))
    if total == 0:
        return 0
    else:
        return float(common) / float(total)


def get_gate_type3(article, summary, mean_overlap):
    overlap = get_overlap(article, summary)
    if overlap < mean_overlap:
        return 0
    else:
        return 1



if __name__=='__main__':

    data = dataset




    meann = []
    for ex in data:
      article = ex['text']
      summary = ex['summary']
      overlap = get_overlap(article.lower(), summary.lower())
      meann.append(overlap)
      mean_overlap = np.mean(meann)


    print(mean_overlap)


    num_0s = 0.
    num_1s = 0.
    num_blank = 0.
    num_1sent = 0.

    for ex in data:
        article = ex['text']
        summary = ex['summary']

        gate = get_gate_type0(article.lower(), summary.lower())
        gate_sent = get_gate_type3(article.lower(), summary.lower(), mean_overlap)


        num_0s += gate.count('0')
        num_1s += gate.count('1')
        num_blank += gate.count('-1')
        num_1sent += gate_sent

    val_df = dataset.map(lambda example: {'gate': get_gate_type0(example['text'], example['summary']),
                                            'gate_sent': get_gate_type3(example['text'], example['summary'], mean_overlap)})

    data_file = open('gazeta_test.csv', 'w')
    csv_writer = csv.writer(data_file)
    count = 0
    for row in val_df:
      if count == 0:
        header = row.keys()
        csv_writer.writerow(header)
        count += 1


      csv_writer.writerow(row.values())

    data_file.close()


print(num_1s/(num_0s + num_1s + num_blank))
print(num_0s/(num_0s + num_1s + num_blank))
print(num_blank/(num_0s + num_1s + num_blank))

print(num_1sent/len(data))